
 
```{r setup, include=T}
knitr::opts_chunk$set(echo = TRUE)
# 检测和安装依赖包
package_list <- c("randomForest","ggplot2","pheatmap")
# 判断R包加载是否成功来决定是否安装后再加载
for(p in package_list){
  if(!suppressWarnings(suppressMessages(require(p, character.only = TRUE, quietly = TRUE, warn.conflicts = FALSE)))){
    install.packages(p)
    suppressWarnings(suppressMessages(library(p, character.only = TRUE, quietly = TRUE, warn.conflicts = FALSE)))
  }
}
library(pheatmap)



```


format2stamp步骤

```{r}
# 1. 读取OTU表
otutab = read.table("C:/16S/result/randomforestclassification/otutab.txt", header=T, row.names= 1, sep="\t", comment.char = "", stringsAsFactors = F)
# 2. 读取物种注释
tax = read.table("C:/16S/result/randomforestclassification/taxonomy.txt", header=T, row.names= 1, sep="\t",comment.char = "", stringsAsFactors = F) 
# 数据按实验设计手动筛选(可选)
metadata_all = read.table("C:/16S/result/randomforestclassification/metadata.txt", header=T, row.names=1, sep="\t") 
# 如筛选soiltypesubspecies列中HIND和HTEJ两组
# sub_metadata = subset(metadata, groupID %in% c("LIND","LTEJ","HIND","HTEJ"))
# sub_metadata = subset(metadata, State %in% c("H","I","D"))
# "DSmed-ISmed" "DEmed-IEmed" "DSmed-HSmed" "DEmed-HEmed" "DSpre-DSmed" "DGpre-DEmed" "DSmed-DSpost" "DEmed-DEpost" "DSpre-DSpost" "DGpre-DEpost" "HSpre-HSmed" "HSmed-HSpost" "HGpre-HEmed" "HEmed-HEpost"
SA = ""
SB = ""
SC = ""
Site_A = "S"
Site_B = "E"
Site_C = "G"
State_A = "H"
State_B = "D"
State_C = "I"
Sday_A = "pre"
Sday_B = "med"
Sday_C = "pre"
#变化下Sday_C变为pre

filetial1 = "rf.txt"
filetial2 = "rf.pdf"
sub_metadatanames = "sub_metadata"
rfcv_names = "rfcv"
importance_names = "importance"
top_f = "top_feautres"
prediction_name = "prediction_binary"
test_names = "test"
class_names = "new"
result_name = "result_S"
output_site = "C:/16S/result/randomforestclassification/"

# result_file_names <- paste(result_name,State_B,State_A,"_new",sep ="_")
# sub_metadata_filename <- paste(sub_metadatanames,Sday_A,State_B,State_A,filetial1,sep ="_")
# rfcv_filename_txt <- paste(class_names,rfcv_names,Sday_A,State_B,State_A,filetial1,sep ="_")
# rfcv_filename_pdf <- paste(class_names,rfcv_names,Sday_A,State_B,State_A,filetial2,sep ="_")
# importance_filename_txt <- paste(class_names,importance_names,Sday_A,State_B,State_A,filetial1,sep ="_")
# top_feautre_filename <- paste(class_names,top_f,Sday_A,State_B,State_A,filetial2,sep ="_")
# prediction_filename <- paste(class_names,prediction_name,Sday_A,State_B,State_A,filetial1,sep ="_")
# testfilename1 <- paste(class_names,test_names,Sday_A,State_B,filetial2,sep ="_")
# testfilename2 <- paste(class_names,test_names,Sday_A,State_A,filetial2,sep ="_")


result_file_names <- paste(result_name,Sday_A,State_A,State_B,"new",sep ="_")
result_file_names <- paste(output_site,result_file_names,sep ="")

sub_metadata_filename <- paste(sub_metadatanames,Sday_A,State_B,State_A,filetial1,sep ="_")
sub_metadata_filename <- paste(output_site,sub_metadata_filename,sep ="")

rfcv_filename_txt <- paste(class_names,rfcv_names,Sday_A,State_B,State_A,filetial1,sep ="_")
rfcv_filename_txt <- paste(output_site,rfcv_filename_txt,sep ="")

rfcv_filename_pdf <- paste(class_names,rfcv_names,Sday_A,State_B,State_A,filetial2,sep ="_")
rfcv_filename_pdf <- paste(output_site,rfcv_filename_pdf,sep ="")

importance_filename_txt <- paste(class_names,importance_names,Sday_A,State_B,State_A,filetial1,sep ="_")
importance_filename_txt <- paste(output_site,importance_filename_txt,sep ="")

top_feautre_filename <- paste(class_names,top_f,Sday_A,State_B,State_A,filetial2,sep ="_")
top_feautre_filename <- paste(output_site,top_feautre_filename,sep ="")

prediction_filename <- paste(class_names,prediction_name,Sday_A,State_B,State_A,filetial1,sep ="_")
prediction_filename <- paste(output_site,prediction_filename,sep ="")

testfilename1 <- paste(class_names,test_names,Sday_A,State_B,filetial2,sep ="_")
testfilename1 <- paste(output_site,testfilename1,sep ="")

testfilename2 <- paste(class_names,test_names,Sday_A,State_A,filetial2,sep ="_")
testfilename2 <- paste(output_site,testfilename2,sep ="")

print(result_file_names)
print(sub_metadata_filename)
print(rfcv_filename_txt)
print(rfcv_filename_pdf)
print(importance_filename_txt)
print(top_feautre_filename)
print(prediction_filename)
print(testfilename1)
print(testfilename2)



# 筛选自己想要的分组以及内容
sub_metadata1 = subset(metadata_all, State %in% c(State_A,State_B))
sub_metadata1
sub_metadata3 = subset(sub_metadata1, Site_1 %in% c(Site_A))
sub_metadata3
sub_metadata2 = subset(sub_metadata3, DayE %in% c(Sday_A,Sday_B))
sub_metadata2

# 实验设计与输入文件交叉筛选。
idx = rownames(sub_metadata2) %in% colnames(otutab)
sub_metadata2 = sub_metadata2[idx,]
sub_metadata2
sub_otutab_tax = otutab[,rownames(sub_metadata2)]
sub_otutab_tax
write.table(sub_metadata2,file = sub_metadata_filename,quote = F,sep = '\t', row.names = T, col.names = T)


# OTU丰度筛选阈值，默认0.1%，0为来筛选
thre = 0.02
# 输出文件名前缀
prefix = "tax_pre_S_DH"

# 生成各分类级汇总特征表
suppressWarnings(suppressMessages(library(amplicon)))
format2stamp(sub_otutab_tax, tax, thre, prefix)
# 在当前目录生成tax_1-8共7个级别+OTU过滤文件

now_dir <- getwd()  # 当前工作目录
aim_dir <- "C:/16S/result/randomforestclassification"

# 创建目标文件夹（如果不存在）
if (!dir.exists(aim_dir)) {
  dir.create(aim_dir, recursive = TRUE)
}

file_patterns <- c("tax_pre_S_DH_1Kingdom", "tax_pre_S_DH_2Phylum", "tax_pre_S_DH_3Class", "tax_pre_S_DH_4Order", 
                   "tax_pre_S_DH_5Family", "tax_pre_S_DH_6Genus", "tax_pre_S_DH_7Species", "tax_pre_S_DH_8OTU0.02")

# 遍历文件模式并移动文件
sapply(file_patterns, function(pattern) {
  files_to_move <- list.files(now_dir, pattern = pattern, full.names = TRUE)
  sapply(files_to_move, function(file) {
    file.copy(file, aim_dir, overwrite = TRUE)
    file.remove(file)
  })
})

# 打印成功信息
print("Files generated and moved to the target directory successfully.")
# 在当前目录生成tax_1-8共7个级别+OTU过滤文件

```




## 训练集，测试集分组
```{r}
# 读取实验设计、和物种分类文件
# 实验用的数据重命名
metadata_f = sub_metadata2
metadata_f

# 设置训练集
train = subset(metadata_f, DayE %in% c("med"))
train

train2 = train
train2
train2$StateSite_1 = as.factor(train2$StateSite_1)
summary(train2)


# 筛选一个合适的分类等级
library(randomForest)
#set.seed(88)
# 自己运行
for(i in c("2Phylum","3Class","4Order","5Family","6Genus","8OTU0.02")){
  # i="5Family"
  set.seed(0)
  table_f = read.table(paste0("C:/16S/result/randomforestclassification/","tax_pre_S_DH_",i,".txt"),header = T, row.names = 1)
  table_f = table_f[,rownames(train2)]
  train2$StateSite_1 = as.factor(train2$StateSite_1)
  rf = randomForest(t(table_f), train2$StateSite_1, importance=T, proximity=T, ntree = 1000)
  print(i)
  print(rf)
}
# OOB estimate of  error rate: 越小越好。
# 本次观察到科水平最准确，选择最准确的水平分析。
```

## 最佳水平数据读取和统计

读取实验设计、Feature表，并进行数据筛选和交叉筛选

```{r}

# 根据之前筛选情况读取物种分类水平数据。读取科水平特征表
table =read.table(paste0("C:/16S/result/randomforestclassification/","tax_pre_S_DH_5Family.txt"),header = T, row.names = 1)
# 筛选L样品作为训练集
# metadata_train = subset(metadata, soiltype %in% c("L"))
# train2重命名，方便后面区分。
metadata_train1 = train2
summary(metadata_train1)

# 筛选OTU
idx = rownames(metadata_train1) %in% colnames(table)
metadata_train1 = metadata_train1[idx,]
otu_sub1 = table[, rownames(metadata_train1)] 
otu_sub1
dim(otu_sub1)
```


## 选择最佳随机数(可选)

```{r}
library(randomForest)
set.seed(77)
for (i in 0:9){
  set.seed(i)
  rf2 = randomForest(t(otu_sub1), metadata_train1$StateSite_1, importance=TRUE, proximity=TRUE, ntree = 1000)
  print(i)
  print(rf2)
}

```

## 随机森林分类

在确定的分类层级和最佳随机数下建模
```{r}
library(randomForest)
set.seed(3)
rf3 = randomForest(t(otu_sub1), metadata_train1$StateSite_1, importance=TRUE, proximity=TRUE, ntree = 1000)
print(rf3)
```

## 交叉验证选择重要特征

```{r}
set.seed(8) # 随机数据保证结果可重复，必须
# rfcv是随机森林交叉验证函数：Random Forest Cross Validation
result = rfcv(t(otu_sub1), metadata_train1$StateSite_1, cv.fold=5)
# 查看错误率表，31时错误率最低，为最佳模型
result$error.cv
# 绘制验证结果 
with(result, plot(n.var, error.cv, log="x", type="o", lwd=2))

# 多次绘制
## 建立数据框保存多次结果
error.cv0 = data.frame(num = result$n.var, error.1 =  result$error.cv)
## 指定随机数循环10次
for (i in 1:(1+9)){
  print(i)
  set.seed(i)
  result= rfcv(t(otu_sub1), metadata_train1$StateSite_1, cv.fold=5) #  scale = "log", step = 0.9
  error.cv0 = cbind(error.cv0, result$error.cv)
}
error.cv0 
```

## 绘制交叉验证曲线

```{r}
# 提取x轴标签
n.var = error.cv0$num
# 提取y轴数据+标签
# error.cv = error.cv0[,2:6]
# colnames(error.cv) = paste('err',1:5,sep='.')
error.cv = error.cv0[,2:11]
colnames(error.cv) = paste('err',1:10,sep='.')


# 添加均值
err.mean = apply(error.cv,1,mean)
# 合并新的数据库，x+error+mean
allerr = data.frame(num=n.var,err.mean=err.mean,error.cv)
# number of otus selected 人为在图中观察的结果，30几乎为最低，且数量可接受
optimal = 20

# 图1：机器学习结果交叉验证图，选择Top features
# 图中 + 5条灰色拆线+1条黑色均值拆线+一条最优垂线+X轴对数变换
write.table(allerr, file = rfcv_filename_txt, sep = "\t", quote = F, row.names = T, col.names = T)

p = ggplot() + # 开始绘图
  geom_line(aes(x = allerr$num, y = allerr$err.1), colour = 'grey') + # 5次验证灰线 
  geom_line(aes(x = allerr$num, y = allerr$err.2), colour = 'grey') + 
  geom_line(aes(x = allerr$num, y = allerr$err.3), colour = 'grey') + 
  geom_line(aes(x = allerr$num, y = allerr$err.4), colour = 'grey') + 
  geom_line(aes(x = allerr$num, y = allerr$err.5), colour = 'grey') + 
  geom_line(aes(x = allerr$num, y = allerr$err.6), colour = 'grey') + # 5次验证灰线 
  geom_line(aes(x = allerr$num, y = allerr$err.7), colour = 'grey') + 
  geom_line(aes(x = allerr$num, y = allerr$err.8), colour = 'grey') + 
  geom_line(aes(x = allerr$num, y = allerr$err.9), colour = 'grey') + 
  geom_line(aes(x = allerr$num, y = allerr$err.10), colour = 'grey') + 
  geom_line(aes(x = allerr$num, y = allerr$err.mean), colour = 'black') + # 均值黑线
  geom_vline(xintercept = optimal, colour='black', lwd=0.36, linetype="dashed") + # 最优垂线
  coord_trans(x = "log2") + # X轴对数变换和刻度
  scale_x_continuous(breaks = c(1, 2, 5, 10, 20, 30, 50, 100, 200)) + # , max(allerr$num)
  labs(title=paste('Training set (n = ', dim(t(otu_sub1))[1],')', sep = ''), 
       x='Number of Classes ', y='Cross-validation error rate') + 
  annotate("text", x = optimal, y = max(allerr$err.mean), label=paste("optimal = ", optimal, sep="")) + theme_bw()
p  
ggsave(p, file = rfcv_filename_pdf, width = 180, height = 120, unit = 'mm')
```

## 特征重要性可视化

```{r}
## 预览和保存特征贡献度
imp= as.data.frame(rf3$importance)
imp = imp[order(imp$MeanDecreaseAccuracy, decreasing = T),]
# bbb = head(imp,n=optimal)
write.table(imp,file = importance_filename_txt,quote = F,sep = '\t', row.names = T, col.names = T)
# 简单可视化，比较丑
# varImpPlot(rf, main = "Feature importance",n.var = optimal, bg = par("bg"), color = par("fg"), gcolor = par("fg"), lcolor = "gray" )

# 图2. Feature重要性：绘制条形图+门属性着色

# 读取所有feature贡献度
imp2 = read.table(importance_filename_txt, header=T, row.names= 1, sep="\t") 
# 分析选择top20分组效果最好，参数显示数量
imp2 = head(imp2, n = optimal)
imp2 = imp2[order(imp2$MeanDecreaseAccuracy, decreasing = F),]
# 简化全名，去掉界
imp2$Family = gsub("Bacteria\\|","",rownames(imp2))
# 添加门用于着色(删除竖线后面全部)
imp2$Phylum = gsub("\\|.*","",imp2$Family)

# 设置顺序
imp2$Family = factor(imp2$Family, levels = imp2$Family)

# 图2. 绘制物种类型种重要性柱状图
p = ggplot(imp2, aes(x = Family, y = MeanDecreaseAccuracy, fill = Phylum)) +   
  geom_bar(stat = "identity") + 
  coord_flip() + theme_bw()
p
ggsave(top_feautre_filename, p, width=89*2.5, height=59*2, unit='mm')
# 名称不一定唯一，需要手动修改

#  简化全名(只保留最后，有重名不可用，可选)
# imp$Family = gsub(".*\\|","",imp$Family)
# imp$Family = factor(imp$Family, levels = imp$Family)
# p = ggplot(imp, aes(x = Family, y = MeanDecreaseAccuracy, fill = Phylum)) +   
#   geom_bar(stat = "identity") + 
#   coord_flip() + theme_bw()
# p
# ggsave(paste("top_feautre",".pdf", sep=""), p, width=89*1.5, height=59*1.5, unit='mm')
```

## 测试集独立验证

如果第一地点数据量足够大，可以取出1/2到1/3进行同一地点的独立验证。方法相同。

筛选测序集样品

```{r}

test = subset(metadata_f, DayE %in% c("pre")) 


#test = metadata_f[!idx3,]
metadata_test = test
summary(metadata_test)
idx4 = rownames(metadata_test) %in% colnames(table)
metadata_test = metadata_test[idx4,]
otu_sub2 = table[,rownames(metadata_test)]



# 转置，并添加分组信息
otutab_t2 = as.data.frame(t(otu_sub2))
otutab_t2$StateSite = metadata_test[rownames(otutab_t2),]$StateSite
```


基于训练集随机森林模型验证

```{r}
set.seed(333)
otutab.pred = predict(rf3, t(otu_sub2) )  
pre_tab = table(observed=otutab_t2[,"StateSite"],
                predicted=otutab.pred) 
pre_tab

```

可视化验证结果

```{r}
# 整理样本原始分组和预测分类
predict = data.frame(group = otutab_t2[,"StateSite"], predicted=otutab.pred)

# 保存预测结果表
write.table("SampleID\t", file=prediction_filename,append = F, quote = F, eol = "", row.names = F, col.names = F)
write.table(predict, file = prediction_filename,append = T, quote = F, row.names = T, col.names = T, sep = "\t")

# 转换为数值可视化
# 预测准确标为1，错误标为0
predict$result = ifelse(predict$group == predict$predicted, 1, 0)
# IND=1, TEJ=2
predict$predict = ifelse(predict$predicted == "DS", 1, 2)
# Set sample number in each row
column1 = 7
column = 7
low_to_high_colors <- colorRampPalette(c("#B1DDE1", "#F8C7BD"))(100)

AA1 = predict[predict$group=="DS",]$predict
length(AA1)
row = round(length(AA1)/column1 + 0.5)
row
i = column1 * row - length(AA1)
AA1 = c(AA1, rep(NA, i))
matrix1 = matrix(AA1, nrow = row, ncol = column1, byrow = T)
pheatmap(matrix1, cluster_rows = F, cluster_cols = F, cellwidth = 15, cellheight = 12, color = low_to_high_colors, border_color = "#EFEFEF")
#pheatmap(matrix1, cluster_rows = F, cluster_cols = F, cellwidth = 15, cellheight = 12,filename = "family_test_DD.pdf")
pheatmap(matrix1, cluster_rows = F, cluster_cols = F, cellwidth = 18, cellheight = 18,filename = testfilename1, color = low_to_high_colors, border_color = "#EFEFEF")
# Draw TEJ prediction result
BB1 = predict[predict$group=="HS",]$predict
length(BB1)
row = round(length(BB1)/column + 0.5)
i = column * row - length(BB1)
BB1 = c(BB1, rep(NA, i))
matrix2 = matrix(BB1, nrow = row, ncol = column, byrow = T)
pheatmap(matrix2, cluster_rows = F, cluster_cols = F, cellwidth = 15, cellheight = 12, color = low_to_high_colors, border_color = "#EFEFEF")
# 保存图片
#pheatmap(matrix2, cluster_rows = F, cluster_cols = F, cellwidth = 18, cellheight = 18, filename = "family_test_HH.pdf")
pheatmap(matrix2, cluster_rows = F, cluster_cols = F, cellwidth = 18, cellheight = 18, filename = testfilename2, color = low_to_high_colors, border_color = "#EFEFEF")



## 将生成的文件放入指定文件夹
source_dir <- "C:/16S/result/randomforestclassification"
target_dir <- result_file_names

if (!dir.exists(target_dir)) {
  dir.create(target_dir)
}

# 选取含特定字符的文件（例如后缀为 csv 的所有文件）
tobeCopy1 <- list.files(source_dir, pattern = "*_rf.txt", full.names = TRUE)
tobeCopy2 <- list.files(source_dir, pattern = "*_rf.pdf", full.names = TRUE)

# 复制选中文件到目标文件夹
sapply(tobeCopy1, function(x) { file.copy(x, target_dir, overwrite = TRUE) })
sapply(tobeCopy2, function(x) { file.copy(x, target_dir, overwrite = TRUE) })

# 删除源文件夹中的已复制文件
file.remove(tobeCopy1)
file.remove(tobeCopy2)

# 确认文件已经复制和删除
print("Files copied and deleted successfully.")





```

使用此脚本，请引用下文：

If used this script, please cited:

**Yong-Xin Liu**, Lei Chen, Tengfei Ma, Xiaofang Li, Maosheng Zheng, Xin Zhou, Liang Chen, Xubo Qian, Jiao Xi, Hongye Lu, Huiluo Cao, Xiaoya Ma, Bian Bian, Pengfan Zhang, Jiqiu Wu, Ren-You Gan, Baolei Jia, Linyang Sun, Zhicheng Ju, Yunyun Gao, **Tao Wen**, **Tong Chen**. 2023. EasyAmplicon: An easy-to-use, open-source, reproducible, and community-based pipeline for amplicon data analysis in microbiome research. **iMeta** 2: e83. https://doi.org/10.1002/imt2.83

Copyright 2016-2023 Yong-Xin Liu <liuyongxin@caas.cn>, Tao Wen <taowen@njau.edu.cn>, Tong Chen <chent@nrc.ac.cn>